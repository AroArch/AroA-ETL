{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpacking of JSON data from DiesDas Indexer Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Projekte/ENC/neues Tool/'\n",
    "src = root + '00_raw_data/'\n",
    "dst = root + '01_unpacked_data/'\n",
    "file = 'raw_IPN_Dachau_Kartei_7_8_1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_attributes(json_objs, attributes):\n",
    "    for record in json_objs:\n",
    "        if type(record) == str:\n",
    "            record = json.loads(record.replace('\\\\\\\\\"','\"'))\n",
    "            \n",
    "        keys = list (record.keys())\n",
    "        for key in keys:\n",
    "            if '_repeat' in key:\n",
    "                get_all_attributes(record[key],attributes)\n",
    "                \n",
    "            else:\n",
    "                attributes.add ((key))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_one_obj(json_obj, output):\n",
    "    \n",
    "    keys = list (json_obj.keys())\n",
    "    for key in keys:\n",
    "        if \"_repeat\" in key:\n",
    "            for obj in json_obj[key]:\n",
    "                extract_data_from_one_obj(obj, output)\n",
    "        else:\n",
    "            if key in result_set:\n",
    "                result_set[key].append (json_obj[key])\n",
    "            else:\n",
    "                result_set[key] = []\n",
    "                result_set[key].append (json_obj[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xstr(s):\n",
    "    return '' if s is None else str(s)\n",
    "\n",
    "\n",
    "def join_stringed_list(column: pd.Series):\n",
    "    return column.apply(\n",
    "        lambda x:', '.join(\n",
    "            [\n",
    "                xstr(v) for v in x\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def unlist_columns(df):\n",
    "    \n",
    "    for col_name in df:\n",
    "        try:\n",
    "            df[col_name] = join_stringed_list(df[col_name])\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df = pd.read_csv(src+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = origin_df['json_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atts = set()\n",
    "get_all_attributes(json_data, atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of lists, attributes are a keys of dict\n",
    "attributes_as_dic = {el:[] for el in atts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpack json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, record in enumerate(json_data):\n",
    "    print(i, end='\\r')\n",
    "    result_set = {}\n",
    "    #record = json.loads(record)\n",
    "    record = json.loads(record.replace('\\\\\\\\\"','\"'))\n",
    "    extract_data_from_one_obj(record, result_set)\n",
    "    for attribute in attributes_as_dic:\n",
    "        if attribute in result_set:\n",
    "            attributes_as_dic[attribute].append(result_set[attribute])\n",
    "        else:\n",
    "            attributes_as_dic[attribute].append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(attributes_as_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperate multiple dates per date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter all date columns with multiple date entries\n",
    "columns = ['birthdate_month', 'birthdate_year', 'birthdate_day']\n",
    "\n",
    "for i, row in output_df.iterrows():\n",
    "    \n",
    "    for column in columns:\n",
    "    \n",
    "        for n, element in enumerate(row[column][:2]):\n",
    "            # print(i, column, element)\n",
    "\n",
    "            output_df.loc[i, f'{column}_{n}'] = element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle multiple persons per classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a field called \"person_list\" is present, unse the following to deal with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in output_df.iterrows():\n",
    "    if i%25==0:\n",
    "        print(i, end='\\r')\n",
    "    \n",
    "    for n, number_dict in enumerate(row['person_list'][0]):\n",
    "        \n",
    "        keys = number_dict.keys()\n",
    "        \n",
    "        for key in keys:\n",
    "            \n",
    "            output_df.loc[i, f'{key}_{n}'] = number_dict[key]\n",
    "        if n == 11:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_list_columns(a,b):\n",
    "    new_list = []\n",
    "    for i, value in enumerate(b):\n",
    "        new_list.append(xstr(a[i])+xstr(b[i]))\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically for Central Name Index (CNI) workflows\n",
    "\n",
    "output_df['person_list'] = pd.Series(list(map(join_list_columns,\n",
    "                output_df['letter'],\n",
    "                output_df['number'])),\n",
    "          index=output_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = unlist_columns(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df = output_df.drop(columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = output_df.reindex(sorted(output_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = origin_df.join(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "export_df.to_csv(dst+'unpacked_'+'_'.join(file.split('_')[1:]), encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
